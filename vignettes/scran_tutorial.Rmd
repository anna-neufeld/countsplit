---
title: "Tutorial: countsplitting and scran" 
output: rmarkdown::html_vignette
bibliography: latent.bib
vignette: >
  %\VignetteIndexEntry{"Scran Tutorial: countsplitting and scran"}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**This tutorial is under construction.**

Before using this tutorial, we recommend that you read through our ``introduction to count splitting" tutorial to understand our method in a simple package with simulated data. 

In this tutorial, we use a real dataset from @elorbany2022single that is also used in our paper. The dataset contains 10,000 cells collected over 15 days of a directed differentiation protocol from induced pluripotent stem cells (IPSC) to cardiomyocytes (cm). 

# Install scran

If you don't already have ``scran``, you will need to run:

```{r, eval=FALSE}
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("scran")
```

Next, you should load the package, along with others that we will use in this tutorial.

```{r, message=FALSE, warning=FALSE}
library(scran)
library(tidyverse)
library(countsplit)
```

# Load the data and perform count splitting

This data is included in this package as a SingleCellExperiment object, so it is simple to load. We will use a few steps from the ``scran`` package.

The main differences between this section and the last is that we will select a subset of highly variable genes and we will estimate and then account for size factors. We use the size factors estimated on the training set in our analysis! This follows our general principle of estimating all the preprocessing on the training set.

We first load the data.

```{r}
data(cm)
```


This is a single cell experiment object.

```{r}
cm
```

The main item in ``cm`` that we care about is the counts matrix, which contains 21,971 genes and 10000 cells. We can view a small subset of it now.

```{r}
dim(counts(cm))
counts(cm)[1:10,1:10]
```

However, there is other important information included in this data. For example, the cells were collected from 19 individuals over the course of 15 days. This info is included in the object!! We don't want to just extract the count matrices and ONLY work with those, because we don't want to lose this info!

```{r}
table(cm$individual)
table(cm$diffday)
```

We now extract the counts and perform count splitting. Note that these are all gene-by-cell matrices- which is different than what we use in our paper. 

```{r}
set.seed(1)
X <- counts(cm)
split <- countsplit(X, epsilon=0.5)
Xtrain <- split$train
Xtest <- split$test
```


# Run preprocessing and clustering on the training set.

Now we want to compute clusters on the training set. But this time, instead of simply running ``kmeans()`` on ``log(Xtrain+1)``, we will use an existing scRNA-seq pipeline from the ``scran`` package that also involves preprocessing steps such as selecting highly variable genes. In order to do this, we need to do some analysis that expects a ``SingleCellExperiment`` object rather than a simple matrix.

All we need to make the ``SingleCellExperiment`` training object is the ``Xtrain`` counts matrix. But it might be nice to retain the metadata in case we need it later. In this case, we do that by copying the original ``cm`` object and then updating the ``counts`` assay. 

Actually in this case I don't need any metadata for my analysis. So I could also just contruct a new scRNAseq object from the counts only. 

```{r}
cm.train <- cm
counts(cm.train) <- Xtrain
```

<!-- Now we are ready for our analysis! These steps were inspired by the [`\textt{scran}``scran`` tutorial](https://bioconductor.org/packages/release/bioc/vignettes/scran/inst/doc/scran.html).  -->
<!-- We first compute sum factors for normalization and then we perform log normalization of the dataset.  -->

<!-- ```{r} -->
<!-- clusters <- quickCluster(cm.train) -->
<!-- cm.train <- computeSumFactors(cm.train, clusters=clusters) -->
<!-- cm.train <- logNormCounts(cm.train) -->
<!-- ``` -->

<!-- We then recide to work only with the top 2000 highly variable features for the remainder of the analysis. As noted in the ``scran`` tutorial, rather than select the top 2000 we could also try to use something like a FDR threshold to select only those that seem significantly variable.  -->

<!-- ```{r} -->
<!-- top.hvgs <- getTopHVGs(modelGeneVar(cm.train), n=2000) -->
<!-- ``` -->

<!-- Finally, we run scran's ``clusterCells`` function, which is a wrapper function for the graph-based clustering steps carried out in the tutorial.  -->

<!-- ```{r} -->
<!-- cm.train<- fixedPCA(cm.train, subset.row=top.hvgs) -->
<!-- clusters.train <- clusterCells(cm.train,use.dimred="PCA") -->
<!-- ``` -->

<!-- It turns out that this function returned 11 clusters. We can visualize them below.  -->

<!-- ```{r,out.width="90%"} -->
<!-- table(clusters.train) -->
<!-- ggplot(as_tibble(reducedDim(cm.train)), aes(x=PC1, y=PC2, col=as.factor(clusters.train)))+geom_point()+labs(col="Cluster") -->
<!-- ``` -->

<!-- # Differential expression testing with Poisson GLMs -->

<!-- We now consider two ways to check differential expression. The first is Poisson GLMs for differentially expressed genes between clusters 1 and 2. We don't need ``Xtest`` to be in a special object for this. For computational efficiency, we don't want to check all 21,000 genes. Let's check 500 randomly selected genes. -->
<!-- Recall that in ``Xtest``, the genes are the rows and not the columns. As in our manuscript, we include size factors as offsets here.  -->

<!-- ```{r, warning=FALSE} -->
<!-- set.seed(1) -->
<!-- indices <- which(clusters.train==1 | clusters.train==2) -->
<!-- genes <- sample(1:NCOL(Xtest), size=500) -->
<!-- results <- t(apply(Xtest[genes, indices], 1, function(u) summary(glm(u~clusters.train[indices], offset=sizeFactors(cm.train)[indices], family="poisson"))$coefficients[2,])) -->
<!-- table(results[,4] < 0.01) -->
<!-- head(results) -->
<!-- ``` -->

<!-- # Differential expression testing with scran -->

<!-- If instead of using our own ``glm`` code we want to use the ``scoreMarkers`` function from the ``scran`` package, as in the scran tutorial, we need to store our test matrix in a ``SingleCellExperiment`` object.  -->

<!-- We can either construct this from scratch using only the count matrix, or we could make a copy of the original ``cm`` object and add the count matrix after. It depends on if we want to be sure to obtain the metadata or not.  -->

<!-- ```{r} -->
<!-- cm.test <- SingleCellExperiment(list(counts=Xtest)) -->
<!-- sizeFactors(cm.test) <- sizeFactors(cm.train) -->
<!-- cm.test <- logNormCounts(cm.test) -->
<!-- ``` -->

<!-- This first element in ``results`` shows marker genes that distinguish cluster 1 from all other clusters. We see that, even with count splitting, there are highly significant marker genes. -->

<!-- ```{r} -->
<!-- results <- scran::findMarkers( -->
<!--   cm.test, groups= clusters.train, -->
<!--   pval.type = "all") -->
<!-- results[[1]] -->
<!-- ``` -->

