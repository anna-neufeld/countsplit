---
title: "Tutorial: countsplitting and scran" 
output: rmarkdown::html_vignette
bibliography: latent.bib
vignette: >
  %\VignetteIndexEntry{"Tutorial: countsplitting and scran"}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Before using this tutorial, we recommend that you read through our [introductory tuorial](https://anna-neufeld.github.io/countsplit/articles/countsplit_tutorial.html) to understand our method in a simple example with simulated data. 

In this tutorial, we use a real dataset from @elorbany2022single. The dataset contains 10,000 cells collected over 15 days of a directed differentiation protocol from induced pluripotent stem cells (IPSC) to cardiomyocytes (cm). 

# Install scran

If you don't already have ``scran``, you will need to run:

```{r, eval=FALSE}
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("scran")
```

Next, you should load the package, along with others that we will use in this tutorial.

```{r, message=FALSE, warning=FALSE}
library(scran)
library(tidyverse)
library(countsplit)
```

# Load the data and perform count splitting

This data is included in this package as a `SingleCellExperiment` object, so it is simple to load. 

```{r}
data(cm)
cm
```

The main item in `cm` that we care about is the counts matrix, which contains 21,971 genes and 10000 cells. We can view a small subset of it now. 

```{r, collapse=TRUE}
dim(counts(cm))
counts(cm)[1:10,1:10]
```

There is other important information included in the `cm` object. For example, the cells were collected from 19 individuals over the course of 15 days. Information on which individual and which day each cell is from is saved within the `cm` object as column data. 

```{r, collapse=TRUE}
table(cm$individual)
table(cm$diffday)
```

To perform count splitting we wish to extract only the count matrix. 

```{r}
set.seed(1)
X <- counts(cm)
split <- countsplit(X, epsilon=0.5)
Xtrain <- split$train
Xtest <- split$test
```


# Run preprocessing and clustering on the training set.

We now wish to compute clusters on the training set. Unlike in our [introductory tuorial](https://anna-neufeld.github.io/countsplit/articles/countsplit_tutorial.html), instead of simply running 
``kmeans()`` on ``log(Xtrain+1)``, we will use an existing scRNA-seq pipeline from the ``scran`` package that also involves preprocessing steps such as selecting highly variable genes. In order to do this, we need to store the training set count matrix `Xtrain` in a `SingleCellExperiment` object. 

We could make a new `SingleCellExperiment` obect that contains only the `Xtrain` counts matrix. However, this would discard all of the metadata that was stored in the `cm` object, such as information regarding which cells where collected on which days and from which individuals. Thus, we chose to let `cm.train`  be a copy of `cm` where we only update the `counts()` attribute. This way, all metadata from `cm` is retained in `cm.train`. 

```{r}
cm.train <- cm
counts(cm.train) <- Xtrain
```

We are now ready to preprocess and cluster this data. The steps used here were inspured by the 

Now we are ready for our analysis! These steps were inspired by the [scran tutorial](https://bioconductor.org/packages/release/bioc/vignettes/scran/inst/doc/scran.html).
We first compute sum factors and then we perform log normalization. 

```{r}
clusters <- quickCluster(cm.train)
cm.train <- computeSumFactors(cm.train, clusters=clusters)
cm.train <- logNormCounts(cm.train)
```

We then compute the top 2000 highly variable genes. While this step does not alter the dimension of `counts(cm.train)`, it allows us to later perform clustering or dimension reduction using only these highly variable genes. 

```{r}
top.hvgs <- getTopHVGs(modelGeneVar(cm.train), n=2000)
```

Finally, we perform dimension reduction on the dataset (using only the highly variable genes), and then cluster the dimension-reduced dataset using scran's `clusterCells` function (which performs graph-based clustering). 

```{r}
cm.train <- fixedPCA(cm.train, subset.row=top.hvgs)
clusters.train <- clusterCells(cm.train,use.dimred="PCA")
```

It turns out that this function returned 11 clusters. We can visualize them below.

```{r,out.width="90%", results='hide', warning=FALSE}
table(clusters.train)
ggplot(as_tibble(reducedDim(cm.train)), aes(x=PC1, y=PC2, col=as.factor(clusters.train)))+geom_point()+labs(col="Cluster")
```

# Differential expression testing with Poisson GLMs

We now consider fitting Poisson GLMs to test for differential expression between clusters 1 and 2. We can do this analysis "by hand", meaning that we do not need to store `Xtest` in a `SingleCellExperiment` object. 

For computational efficiency, we test 500 randomly selected genes for differential expression, rather than checking all 21,000 genes. The first step is to subset the test data to only include these 500 genes and to only include cells that were placed in cluster 1 or cluster 2. We will include size factors for each cell, estimated on the training set, as offsets in our Poisson GLM. We need to obtain the appropriate size factor vector and subset it to only include the cells that were placed in cluster 1 or cluster 2. We do these steps below.

```{r, warning=FALSE, collapse=TRUE}
set.seed(1)
indices <- which(clusters.train==1 | clusters.train==2)
genes <- sample(1:NCOL(Xtest), size=500) 
Xtestsubset <- Xtest[genes, indices]
sizefactors.subset <- sizeFactors(cm.train)[indices]
```

We are now ready to test for differential expression. We see that 61 out of our 500 genes were identified as significantly differentially expressed at alpha=0.01. 

```{r, warning=FALSE, collapse=TRUE}
results <- t(apply(Xtestsubset, 1, function(u) summary(glm(u~clusters.train[indices], offset=log(sizefactors.subset), family="poisson"))$coefficients[2,]))
table(results[,4] < 0.01) 
```

We can view the names of these highly significant genes below. 

```{r, warning=FALSE, collapse=TRUE}
head(results[results[,4] < 0.01,], n=10)
```

# Differential expression testing with scran

In this section, instead of testing for differential expression "by hand" using `glm()`, we use the `scoreMarkers()` function from the scran package. This is the method used in the [scran tutorial](https://bioconductor.org/packages/release/bioc/vignettes/scran/inst/doc/scran.html#6_Identifying_marker_genes), in the section titled "Find Marker Genes". 

In order to use the `scoreMarkers()` function, we need to store our test matrix in a ``SingleCellExperiment`` object.  We can either construct this from scratch using only the count matrix, or we could make a copy of the original ``cm`` object and add the count matrix after. Since we do not anticipate needing any metadata in this section, we construct the obecjt from scratch. 

```{r}
cm.test <- SingleCellExperiment(list(counts=Xtest))
```

The `scoreMarkers()` function needs access to the log-normalized counts assay (`logcounts()`) in the `cm.test` object. To fill in this assay, we need to run the `logNormCounts` function on `cm.test`. We would like to normalize the test matrix using size factors computed on the training set (this follows our general philosophy of performing all preprocessing steps on the training set). Thus, we obtain size factors from the training set before calling `logNormCounts()`. 

```{r}
sizeFactors(cm.test) <- sizeFactors(cm.train)
cm.test <- logNormCounts(cm.test) 
```

This first element in ``results`` shows marker genes that distinguish cluster 1 from all other clusters. We see that, even with count splitting, there are highly significant marker genes. 

```{r}
results <- scran::findMarkers( 
cm.test, groups= clusters.train,
 pval.type = "all") 
results[[1]]
``` 

Even with count splitting, we identify several highly significant marker genes, both "by hand" and with the `findMarkers()` function. 

# References

