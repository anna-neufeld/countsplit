# Generate binomial data
X <- matrix(0, nrow=n, ncol=d)
X[] <- rbinom(n*d, N, p)
maxPC <- 20
maxf <- 5
n <- 250
d <- 100
nPC <- 10
sval <- 14:5
set.seed(1)
Upop <- pracma::randortho(n)[,1:nPC]
Dpop <- diag(sval)
Vpop <- pracma::randortho(d)[,1:nPC]
logitp <- Upop%*%Dpop%*%t(Vpop)
N <- 100
p <- plogis(logitp)
# Generate binomial data
X <- matrix(0, nrow=n, ncol=d)
X[] <- rbinom(n*d, N, p)
set.seed(1)
X <- matrix(0, nrow=n, ncol=d)
X[] <- rbinom(n*d, N, p)
set.seed(1)
X2 <- matrix(rbinom(n*d, N, p), nrow=n, ncol=d)
all.equal(X1, X2)
all.equal(X, X2)
maxPC <- 20
maxf <- 5
n <- 250
d <- 100
nPC <- 10
sval <- 14:5
set.seed(1)
Upop <- pracma::randortho(n)[,1:nPC]
Dpop <- diag(sval)
Vpop <- pracma::randortho(d)[,1:nPC]
logitp <- Upop%*%Dpop%*%t(Vpop)
N <- 100
p <- plogis(logitp)
# Generate binomial data
X <- matrix(rbinom(n*d, N, p), nrow=n, ncol=d)
# Data Thinning (0.5)
eps <- 0.5
sp <- binomsplit(X, epsilon=eps, pop=N)
Ndt <- N*eps
p.hat <- (sp$Xtr+0.001)/(Ndt+0.002)
logitp.hat <- qlogis(p.hat)
dt.svd <- svd(logitp.hat)
## Compute the binomial PCA rank-K reconstruction MSE loss
recon.bin <- function(dat, lpsvd, N, k) {
U <- lpsvd$u
d <- lpsvd$d
V <- lpsvd$v
if (k == 1) {
approx <- U[,1:k, drop='F']%*%(d[1:k])%*%t(V[,1:k, drop='F'])
} else {
approx <- U[,1:k]%*%diag(d[1:k])%*%t(V[,1:k])
}
approx2 <- N * plogis(approx)
return(mean((dat-approx2)^2))
}
maxPC <- 20
maxf <- 5
n <- 250
d <- 100
nPC <- 10
sval <- 14:5
set.seed(1)
Upop <- pracma::randortho(n)[,1:nPC]
Dpop <- diag(sval)
Vpop <- pracma::randortho(d)[,1:nPC]
logitp <- Upop%*%Dpop%*%t(Vpop)
N <- 100
p <- plogis(logitp)
# Generate binomial data
X <- matrix(rbinom(n*d, N, p), nrow=n, ncol=d)
# Data Thinning (0.5)
eps <- 0.5
sp <- binomsplit(X, epsilon=eps, pop=N)
Ndt <- N*eps
p.hat <- (sp$Xtr+0.001)/(Ndt+0.002)
sp <- datathin(X, family="binomial", epsilon=eps, arg=N)
Ndt <- N*eps
p.hat <- (sp$Xtr+0.001)/(Ndt+0.002)
logitp.hat <- qlogis(p.hat)
dt.svd <- svd(logitp.hat)
results_binom <- rep(NA, maxPC)
for (j in 1:maxPC) {
# Compute reconstruction errors and save results
results_binom[j] <- recon.bin(sp$Xte, dt.svd, Ndt*(1-eps)/eps, j)
}
eps <- 0.8
sp <- binomsplit(X, epsilon=eps, pop=N)
Ndt <- N*eps
p.hat <- (sp$Xtr+0.001)/(Ndt+0.002)
# Data Thinning (0.5)
eps <- 0.5
sp <- datathin(X, family="binomial", epsilon=eps, arg=N)
Ndt <- N*eps
p.hat <- (sp$Xtr+0.001)/(Ndt+0.002)
logitp.hat <- qlogis(p.hat)
dt.svd <- svd(logitp.hat)
results_binom <- rep(NA, maxPC)
for (j in 1:maxPC) {
# Compute reconstruction errors and save results
results_binom[j] <- recon.bin(sp$Xte, dt.svd, Ndt*(1-eps)/eps, j)
}
eps <- 0.8
sp <- datathin(X, family="binomial", epsilon=eps, arg=N)
Ndt <- N*eps
p.hat <- (sp$Xtr+0.001)/(Ndt+0.002)
logitp.hat <- qlogis(p.hat)
dt.svd <- svd(logitp.hat)
results_binom_0.8 <- rep(NA, maxPC)
for (j in 1:maxPC) {
# Compute reconstruction errors and save results
results_binom_0.8[j] <- recon.bin(sp$Xte, dt.svd, Ndt*(1-eps)/eps, j)
}
plot(results_binom)
ggplot(data=NULL)+
geom_line(aes(x=1:maxPC, y=results_binom))+
geom_line(aes(x=1:maxPC, y=results_binom_0.8))+
geom_vline(xintercept=nPC, col="red")
source("~/countsplit/R/countsplit.R")
### Parameters for simulation.
n <- 1000
p <- 1000
B1s <- 1
overdisps <- 5
K <- 3
clustTry = 1:10
### Generate a dataset!
set.seed(1)
B0s <- rnorm(current_dynamic_args$p)
clusters <- sample(1:K, size=n, replace=TRUE)
logLambda <- matrix(B0s, nrow=n, ncol=p, byrow = TRUE)
c <- 1
if (K > 1) {
for (clust in 1:(K-1)) {
logLambda[clusters==clust,c:(c+p/20-1)] <-  logLambda[clusters==clust,c:(c+p/20-1)]+B1
c <- c+p/20
}
}
Lambda <- exp(logLambda)
Lambda_bar_js <- colMeans(Lambda)
overdisps <- sapply(Lambda_bar_js, function(u) u/overdisp)
X <- sapply(1:p, function(u) rnbinom(length(Lambda[,u]), mu=Lambda[,u], size=overdisps[u]))
#### Do count splitting to estimate the number of clusters! Here we assume that the
#### overdispersion values are unknown and so we use sctransform.
### First, I wrote my own sctransform wrapper function.
get_sctransform_bs <- function(X) {
rownames(X) <- 1:NROW(X)
colnames(X) <- 1:NCOL(X)
#### This uses all of sctransform's default settings.
fit <- sctransform::vst(t(X), verbosity=0, min_cells=0)
#### I want to make sure that it returns me an estimated overdispersion for EVERY gene.
#### by default, it drops the ones that are estimated to be Poisson.
#### I add them back in, with an overdisp of infinity.
b_j1 <- fit$model_pars_fit[,1]
if (length(b_j1) != NCOL(X)) {
temp <- b_j1
b_j1 <- rep(Inf, NCOL(X))
b_j1[rownames(temp)] <- temp
}
return(b_j1)
}
overdisps.sct <- get_sctransform_bs(X)
Xsplit <- nb.countsplit(X, epsilon=0.5, overdisps=overdisps.sct)
source("~/countsplit/R/countsplit.R")
### Parameters for simulation.
n <- 1000
p <- 1000
B1s <- 1
overdisps <- 5
K <- 3
clustTry = 1:10
### Generate a dataset!
set.seed(1)
B0s <- rnorm(current_dynamic_args$p)
clusters <- sample(1:K, size=n, replace=TRUE)
### Generate a dataset!
set.seed(1)
B0s <- rnorm(p)
clusters <- sample(1:K, size=n, replace=TRUE)
logLambda <- matrix(B0s, nrow=n, ncol=p, byrow = TRUE)
c <- 1
if (K > 1) {
for (clust in 1:(K-1)) {
logLambda[clusters==clust,c:(c+p/20-1)] <-  logLambda[clusters==clust,c:(c+p/20-1)]+B1
c <- c+p/20
}
}
B1 <- 1
if (K > 1) {
for (clust in 1:(K-1)) {
logLambda[clusters==clust,c:(c+p/20-1)] <-  logLambda[clusters==clust,c:(c+p/20-1)]+B1
c <- c+p/20
}
}
Lambda <- exp(logLambda)
Lambda_bar_js <- colMeans(Lambda)
overdisps <- sapply(Lambda_bar_js, function(u) u/overdisp)
X <- sapply(1:p, function(u) rnbinom(length(Lambda[,u]), mu=Lambda[,u], size=overdisps[u]))
overdisp <- 5
overdisps <- sapply(Lambda_bar_js, function(u) u/overdisp)
X <- sapply(1:p, function(u) rnbinom(length(Lambda[,u]), mu=Lambda[,u], size=overdisps[u]))
### First, I wrote my own sctransform wrapper function.
get_sctransform_bs <- function(X) {
rownames(X) <- 1:NROW(X)
colnames(X) <- 1:NCOL(X)
#### This uses all of sctransform's default settings.
fit <- sctransform::vst(t(X), verbosity=0, min_cells=0)
#### I want to make sure that it returns me an estimated overdispersion for EVERY gene.
#### by default, it drops the ones that are estimated to be Poisson.
#### I add them back in, with an overdisp of infinity.
b_j1 <- fit$model_pars_fit[,1]
if (length(b_j1) != NCOL(X)) {
temp <- b_j1
b_j1 <- rep(Inf, NCOL(X))
b_j1[rownames(temp)] <- temp
}
return(b_j1)
}
overdisps.sct <- get_sctransform_bs(X)
X
class(X)
rownames(X) <- 1:NROW(X)
colnames(X) <- 1:NCOL(X)
#### This uses all of sctransform's default settings.
fit <- sctransform::vst(t(X), verbosity=0, min_cells=0)
overdisps.sct <- get_sctransform_bs(X)
Xsplit <- nb.countsplit(X, epsilon=0.5, overdisps=overdisps.sct)
knitr::opts_chunk$set(echo = TRUE, collapse=TRUE, message=FALSE, warning=FALSE)
knitr::include_graphics("fig2_screenshot.png")
knitr::include_graphics("Untitled.png")
set.seed(1)
### Number of cells
n <- 500
### Number of genes
p <- 2
#### Generate data from a negative binomial distribution, where all cells and
#### all genes have mean 7 and overdispersion parameter 7.
#### *very boring data*.
Xnull <- matrix(rnbinom(n*p, size=7, mu=7),ncol=p)
ggplot(data=NULL, aes(x=Xnull[,1]+1, y=Xnull[,2]+1))+geom_point()+
theme_bw()+coord_fixed()+scale_y_log10()+scale_x_log10()+
xlab("")+ylab("")+
theme(panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
axis.text=element_text(size=16))
set.seed(1)
### Number of cells
n <- 500
### Number of genes
p <- 2
#### Generate data from a negative binomial distribution, where all cells and
#### all genes have mean 7 and overdispersion parameter 7.
#### *very boring data*.
Xnull <- matrix(rnbinom(n*p, size=7, mu=7),ncol=p)
library(ggplot2)
ggplot(data=NULL, aes(x=Xnull[,1]+1, y=Xnull[,2]+1))+geom_point()+
theme_bw()+coord_fixed()+scale_y_log10()+scale_x_log10()+
xlab("")+ylab("")+
theme(panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
axis.text=element_text(size=16))
ggplot(data=NULL, aes(x=Xnull[,1]+1, y=Xnull[,2]+1))+geom_point()+
theme_bw()+coord_fixed()+scale_y_log10()+scale_x_log10()+
xlab("")+ylab("")+
theme(panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
axis.text=element_text(size=16))
clusters <- kmeans(log(Xnull+1), centers=5)$cluster
ggplot(data=NULL, aes(x=Xnull[,1]+1, y=Xnull[,2]+1, col=clusters))+geom_point()+
theme_bw()+coord_fixed()+scale_y_log10()+scale_x_log10()+
xlab("")+ylab("")+
theme(panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
axis.text=element_text(size=16))
clusters <- kmeans(log(Xnull+1), centers=5)$cluster
ggplot(data=NULL, aes(x=Xnull[,1]+1, y=Xnull[,2]+1, col=clusters))+geom_point()+
theme_bw()+coord_fixed()+scale_y_log10()+scale_x_log10()+
xlab("")+ylab("")+
theme(panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
axis.text=element_text(size=16))
clusters <- as.factor(kmeans(log(Xnull+1), centers=5)$cluster)
ggplot(data=NULL, aes(x=Xnull[,1]+1, y=Xnull[,2]+1, col=clusters))+geom_point()+
theme_bw()+coord_fixed()+scale_y_log10()+scale_x_log10()+
xlab("")+ylab("")+
theme(panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
axis.text=element_text(size=16))
Y <- log(Xnull+1)
numClust <- 5
clusterLabs <- kmeans(Y, centers=numClust, nstart=50)$cluster
confusionMatrix <- matrix(0, nrow=numClust, ncol=numClust)
crossValIndices <- sample(1:n, size=n, replace=FALSE)
counter <- 1
for (f in 1:folds) {
testIndices <-  crossValIndices[counter:(counter+n/folds-1)]
counter <- counter+n/folds
Ytrain <- Y[-testIndices,]
Ytest <- Y[testIndices,]
clustersTrain <- clusterLabs[-testIndices]
clustersTest <- clusterLabs[testIndices]
classifier <- e1071::svm(x=Ytrain, y=as.factor(clustersTrain), kernel="linear")
preds <- predict(classifier, newdata=Ytest)
confusionMatrix <- confusionMatrix + table(preds, clustersTest)
}
Y <- log(Xnull+1)
numClust <- 5
folds <- 5
clusterLabs <- kmeans(Y, centers=numClust, nstart=50)$cluster
confusionMatrix <- matrix(0, nrow=numClust, ncol=numClust)
crossValIndices <- sample(1:n, size=n, replace=FALSE)
counter <- 1
for (f in 1:folds) {
testIndices <-  crossValIndices[counter:(counter+n/folds-1)]
counter <- counter+n/folds
Ytrain <- Y[-testIndices,]
Ytest <- Y[testIndices,]
clustersTrain <- clusterLabs[-testIndices]
clustersTest <- clusterLabs[testIndices]
classifier <- e1071::svm(x=Ytrain, y=as.factor(clustersTrain), kernel="linear")
preds <- predict(classifier, newdata=Ytest)
confusionMatrix <- confusionMatrix + table(preds, clustersTest)
}
ggplot(data=data.frame(confusionMatrix ), aes(x= clustersTest, y= preds, fill=Freq))+geom_tile()+
ggtitle("Naive method; no true clusters")+xlab("Cluster predicted by SVM")+ylab("Cluster estimated with kmeans")
ggplot(data=data.frame(confusionMatrix ), aes(x= clustersTest, y= preds, fill=Freq))+geom_tile()+
ggtitle("Naive method; no true clusters")+xlab("Cluster predicted by SVM")+ylab("Cluster estimated with kmeans")
sum(diag(confusionMatrix))/sum(confusionMatrix)
?knitr::include_graphics
PLknitr::include_graphics("fig2_screenshot.png")
knitr::include_graphics("fig2_screenshot.png")
knitr::include_graphics("Untitled.png")
knitr::include_graphics("fig2_screenshot.png","Untitled.png")
knitr::include_graphics("Untitled.png")
knitr::opts_chunk$set(echo = TRUE, collapse=TRUE, message=FALSE, warning=FALSE)
library(ggplot2)
clusters <- as.factor(kmeans(log(Xnull+1), centers=5)$cluster)
ggplot(data=NULL, aes(x=Xnull[,1]+1, y=Xnull[,2]+1, col=clusters))+geom_point()+
theme_bw()+coord_fixed()+scale_y_log10()+scale_x_log10()+
xlab("X1")+ylab("X2")+
theme(panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
axis.text=element_text(size=16))
set.seed(1)
### Number of cells
n <- 500
### Number of genes
p <- 2
#### Generate data from a negative binomial distribution, where all cells and
#### all genes have mean 7 and overdispersion parameter 7.
#### *very boring data*.
Xnull <- matrix(rnbinom(n*p, size=7, mu=7),ncol=p)
ggplot(data=NULL, aes(x=Xnull[,1]+1, y=Xnull[,2]+1))+geom_point()+
theme_bw()+coord_fixed()+scale_y_log10()+scale_x_log10()+
xlab("")+ylab("")+
theme(panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
axis.text=element_text(size=16))
set.seed(1)
### Number of cells
n <- 500
### Number of genes
p <- 2
#### Generate data from a negative binomial distribution, where all cells and
#### all genes have mean 7 and overdispersion parameter 7.
#### *very boring data*.
Xnull <- matrix(rnbinom(n*p, size=7, mu=7),ncol=p)
ggplot(data=NULL, aes(x=Xnull[,1]+1, y=Xnull[,2]+1))+geom_point()+
theme_bw()+scale_y_log10()+scale_x_log10()+
xlab("X1")+ylab("X2")+
theme(panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),
axis.text=element_text(size=16))
x <- sample(1:6, size=100000, replace=TRUE)
hist(x, breaks=1:6, right=FALSE, freq=TRUE)
hist(x, breaks=seq(0.5, 6.5, length.out=6), right=FALSE, freq=TRUE)
hist(x, breaks=seq(0.4, 6.4, length.out=6), right=FALSE, freq=TRUE)
x <- sample(1:6, size=100000, replace=TRUE)
hist(x, breaks=seq(0.5, 6.5, length.out=7), right=FALSE, freq=TRUE)
x <- sample(1:6, size=100000, replace=TRUE)
hist(x, breaks=seq(0.5, 6.5, length.out=7), right=FALSE, freq=FALSE)
y <- sapply(1:10000, max(sample(1:6, size=6, replace=TRUE)))
hist(y, breaks=seq(0.5, 6.5, length.out=7), right=FALSE, freq=FALSE)
y <- sapply(1:10000, max(sample(1:6, size=6, replace=TRUE)))
y <- sapply(1:10000, max(sample(1:6, size=6, replace=TRUE)))
sample(1:6, size=6, replace=TRUE)
y <- replicate(100000, max(sample(1:6, size=6, replace=TRUE))))
y <- replicate(100000, max(sample(1:6, size=6, replace=TRUE)))
hist(y, breaks=seq(0.5, 6.5, length.out=7), right=FALSE, freq=FALSE)
x <- sample(1:6, size=100000, replace=TRUE)
hist(x, breaks=seq(0.5, 6.5, length.out=14), right=FALSE, freq=FALSE)
y <- replicate(100000, max(sample(1:6, size=6, replace=TRUE)))
hist(y, breaks=seq(0.5, 6.5, length.out=14), right=FALSE, freq=FALSE)
z <- replicate(100000, mean(sample(1:6, size=6, replace=TRUE)))
hist(z, breaks=seq(0.5, 6.5, length.out=14), right=FALSE, freq=FALSE)
y <- replicate(100000, mean(sample(1:6, size=6, replace=TRUE)))
hist(y, breaks=seq(0.5, 6.5, length.out=14), right=FALSE, freq=FALSE)
z <- replicate(100000, max(sample(1:6, size=6, replace=TRUE)))
hist(z, breaks=seq(0.5, 6.5, length.out=14), right=FALSE, freq=FALSE)
x <- rnorm(40000, mu=58, sd=4)
x <- rnorm(40000, mu=58, sd=4)
x <- rnorm(40000, mean=58, sd=4)
hist(x, breaks=seq(0.5, 6.5, length.out=14), right=FALSE, freq=FALSE)
x <- rnorm(40000, mean=58, sd=4)
hist(x, right=FALSE, freq=FALSE)
x <- rnorm(40000, mean=58, sd=5)
hist(x, right=FALSE, freq=FALSE)
x <- rnorm(40000, mean=58, sd=5)
hist(x, right=FALSE, freq=FALSE)
abline(v=58, col="red")
x <- rnorm(40000, mean=58, sd=5, xlim=c(40,80))
hist(x, right=FALSE, freq=FALSE)
x <- rnorm(40000, mean=58, sd=5)
hist(x, right=FALSE, freq=FALSE,xlim=c(40,80))
abline(v=58, col="red")
abline(v=58, col="red", lwd=3)
hist(z, right=FALSE, freq=FALSE, xlim=c(40,80))
y <- replicate(100000, mean(sample(x, size=6, replace=TRUE)))
z <- replicate(100000, max(sample(x, size=6, replace=TRUE)))
hist(z, right=FALSE, freq=FALSE, xlim=c(40,80))
y <- replicate(100000, mean(sample(x, size=6, replace=TRUE)))
hist(y, right=FALSE, freq=FALSE)
y <- replicate(100000, mean(sample(x, size=6, replace=TRUE)))
hist(y, right=FALSE, freq=FALSE,xlim=c(40,80))
abline(v=58, col="red", lwd=3)
y <- replicate(100000, mean(sample(x, size=10, replace=TRUE)))
hist(y, right=FALSE, freq=FALSE,xlim=c(40,80))
abline(v=58, col="red", lwd=3)
x <- c(rep(0,10000), rnorm(10000, 10, sd=4), rnorm(10000, 100, sd=20),
rpois(10000, 200))
hist(x, right=FALSE, freq=FALSE,xlim=c(40,80))
abline(v=mean(x), col="red", lwd=3)
x <- c(rep(0,10000), rnorm(10000, 10, sd=4), rnorm(10000, 100, sd=20),
rpois(10000, 200))
hist(x, right=FALSE, freq=FALSE,xlim=c(0,max(x)))
x <- c(rep(0,10000), rnorm(10000, 10, sd=4), rnorm(10000, 100, sd=20),
rpois(10000, 200), 1000)
hist(x, right=FALSE, freq=FALSE,xlim=c(0,max(x)))
x <- c(rep(0,10000), rnorm(10000, 10, sd=4), rnorm(10000, 100, sd=20),
rpois(10000, 200))
hist(x, right=FALSE, freq=FALSE,xlim=c(0,max(x)))
x <- c(rep(0,10000), rnorm(10000, 10, sd=4), rnorm(10000, 100, sd=20),
rpois(1000, 250))
hist(x, right=FALSE, freq=FALSE,xlim=c(0,max(x)))
abline(v=mean(x), col="red", lwd=3)
y <- replicate(100000, mean(sample(x, size=10, replace=TRUE)))
hist(y, right=FALSE, freq=FALSE,xlim=c(0,max(x)))
abline(v=58, col="red", lwd=3)
y10 <- replicate(100000, mean(sample(x, size=10, replace=TRUE)))
hist(y10, right=FALSE, freq=FALSE,xlim=c(0,max(x)))
abline(v=58, col="red", lwd=3)
y100 <- replicate(100000, mean(sample(x, size=100, replace=TRUE)))
hist(y10, right=FALSE, freq=FALSE,xlim=c(0,max(x)))
abline(v=58, col="red", lwd=3)
hist(y100, right=FALSE, freq=FALSE,xlim=c(0,max(x)))
abline(v=58, col="red", lwd=3)
y10 <- replicate(100000, mean(sample(x, size=10, replace=TRUE)))
hist(y10, right=FALSE, freq=FALSE,xlim=c(0,max(x)))
abline(v=mean(x), col="red", lwd=3)
y100 <- replicate(100000, mean(sample(x, size=100, replace=TRUE)))
hist(y100, right=FALSE, freq=FALSE,xlim=c(0,max(x)))
abline(v=mean(x), col="red", lwd=3)
setwd("~/countsplit.tutorials")
pkgdown::buils_site(lazy=TRUE)
pkgdown::build_site(lazy=TRUE)
setwd("~/countsplit")
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
setwd("~/countsplit.tutorials")
pkgdown::build_site()
pkgdown::build_site(lazy=TRUE)
library(countsplit)
nb.countsplit
remotes::install_github("anna-neufeld/countsplit")
library(countsplit)
library(ggplot2)
library(patchwork)
nb.countsplit()
?countsplit::nb.countsplit
nb.countsplit
library(countsplit)
nb.countsplit
countsplit::nb.countsplit()
countsplit::nb.countsplit
setwd("~/countsplit")
devtools::check()
devtools::build()
countsplit::nb.countsplit
set.seed(1)
n <- 2000
p <- 500
X <- matrix(rnbinom(n*p, mu=5, size=5), nrow=n)
split <- nb.countsplit(X, epsilon=0.5, overdisps=rep(5,p))
split <- nb.countsplit(X, epsilon=0.5, overdisps=rep(5,p))
Xtrain <- split$train
Xtest <- split$test
sapply(1:u, function(u) cor(Xtrain[,u], Xtest[,u]))
split <- nb.countsplit(X, epsilon=0.5, overdisps=rep(5,p))
Xtrain <- split$train
Xtest <- split$test
sapply(1:p, function(u) cor(Xtrain[,u], Xtest[,u]))
split <- nb.countsplit(X, epsilon=0.5, overdisps=rep(5,p))
Xtrain <- split$train
Xtest <- split$test
cors <- sapply(1:p, function(u) cor(Xtrain[,u], Xtest[,u]))
hist(cors)
